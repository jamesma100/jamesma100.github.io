---
layout: post
title: "Why is mmap slow?"
---

It's quite common to need to read some file from disk and copy it somewhere, e.g. a network socket.
Generally, this is done with the `read` and `write` syscalls, a convenient filesystem abstraction for disk I/O.

However, a lot is happening behind the scenes that may slow you down.
As you might already know, your operating system usually does not let you access physical storage directly.
Rather, every I/O request goes through the kernel, which facilitates the communication with external devices.

This has lots of benefits that we won't discuss here, but comes with a large overhead, particularly with respect to data copying and context switching between the user and kernel modes.

For instance, if we wanted to copy a file to another location, one might do something like below.
```
int fd_in = open(file_in, O_RDONLY);
struct stat statbuf;
fstat(fd_in, &statbuf); // get size of file
void *ptr = malloc(statbuf.st_size);
read(fd_in, ptr, statbuf.st_size);
int fd_out = open(file_out, O_RDWR | O_CREAT, 0666);
write(fd_out, ptr, statbuf.st_size);
free(ptr);
close(fd_in);
close(fd_out);
```

This seems benign enough, but internally, our data gets copied four times.

On read, the first copy is done from your disk to a kernel buffer via DMA (assuming it is not already in the pagecache from a previous read).
A second copy occurs as data is transferred to the user buffer we allocated via `malloc`.
During the write, the kernel copies data for the third time from our user buffer into kernel memory, then passes it on to the disk controller, requiring a final fourth copy.

The large number of copies wastes memory and and can stall our programs if the CPU is waiting on the syscalls to return.
Even if our writes are done asynchronously (i.e. without the use of `fsync`), we still need to wait for the third copy into kernel memory to complete.

Copying a 1GiB file 10 times takes nearly a minute and a half on my machine.
```
./write_large_file
time ./rw large_file.txt output.txt 10

real	1m16.079s
user	0m0.000s
sys	0m7.312s
```
## Memory mapping
We can improve the above code with memory mapping. 
Memory mapping allows you to map some portion of your virtual address space to some portion of kernel memory and operate on that memory directly.
Doing this, we can avoid one copy into userspace on read.
On write, we can operate entirely in the kernel, copying the file from the first kernel buffer to the second.
Altogether, we avoid one copy, a sizable improvement especially when your file is large.

```
int fd_in = open(file_in, O_RDONLY);
struct stat statbuf;
fstat(fd_in, &statbuf);
char *ptr_in = mmap(NULL, statbuf.st_size, PROT_READ, MAP_PRIVATE, fd_in, 0);
int fd_out = open(file_out, O_RDWR | O_CREAT, 0666);
ftruncate(fd_out, statbuf.st_size); // set size of created file

char *ptr_out = mmap(NULL, statbuf.st_size, PROT_WRITE, MAP_SHARED, fd_out, 0);
memcpy(ptr_out, ptr_in, statbuf.st_size); // copy data into mapped region
munmap(ptr_in, statbuf.st_size);
munmap(ptr_out, statbuf.st_size);
close(fd_in);
close(fd_out);
```

Copying the same 1GiB file with `mmap` takes 

#### The trouble with mmap
...

## Using sendfile

Notice that mmap allows us to map our virtual address space to the kernel's page cache so that we can write to it without going through a separate copy.
But if we don't need to do any processing on our file, we can bypass the userspace mapping entirely!

The `sendfile` syscall does exactly that, copying data from one file descriptor to another.
This is commonly done to send data over the network, but also works in the case of writing to a file.

Notice that we still require one copy, but avoid the overhead of the memory-mapping.

```
int fd_in = open(file_in, O_RDONLY);
struct stat statbuf;
fstat(fd_in, &statbuf);

int fd_out = open(file_out, O_WRONLY | O_CREAT, 0666);
sendfile(fd_out, fd_in, NULL, statbuf.st_size);
close(fd_in);
close(fd_out);
```
